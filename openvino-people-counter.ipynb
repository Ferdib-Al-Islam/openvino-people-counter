{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL=/opt/intel/openvino/deployment_tools/tools/model_downloader/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/person-detection-retail-0013.xml\n",
    "%env DEVICE=CPU\n",
    "%env CPU_EXTENSION=/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so\n",
    "%env INPUT=resources/Pedestrain_Detect_2_1_1.mp4\n",
    "%env PERF_COUNTS=0\n",
    "%env PROB_THRESHOLD=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"People Counter.\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit person to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import socket\n",
    "import json\n",
    "import cv2\n",
    "import subprocess\n",
    "import logging as log\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "from inference import Network\n",
    "\n",
    "# MQTT server environment variables\n",
    "HOSTNAME = socket.gethostname()\n",
    "IPADDRESS = socket.gethostbyname(HOSTNAME)\n",
    "MQTT_HOST = IPADDRESS\n",
    "MQTT_PORT = 1884\n",
    "MQTT_KEEPALIVE_INTERVAL = 60\n",
    "\n",
    "try:\n",
    "    # Probability threshold for detections filtering\n",
    "    prob_threshold = float(os.environ['PROB_THRESHOLD'])\n",
    "except:\n",
    "    prob_threshold = 0.5\n",
    "\n",
    "\n",
    "def performance_counts(perf_count):\n",
    "    \"\"\"\n",
    "    print information about layers of the network.\n",
    "\n",
    "    :param perf_count: Dictionary describing the status of the layers\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    print(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format('name', 'layer_type',\n",
    "                                                      'exec_type', 'status',\n",
    "                                                      'real_time, us'))\n",
    "    for layer, stats in perf_count.items():\n",
    "        print(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format(layer,\n",
    "                                                          stats['layer_type'],\n",
    "                                                          stats['exec_type'],\n",
    "                                                          stats['status'],\n",
    "                                                          stats['real_time']))\n",
    "\n",
    "\n",
    "def ssd_parser(frame, result):\n",
    "    \"\"\"\n",
    "    parses the ssd output\n",
    "\n",
    "    :param frame: frame from camera/video\n",
    "    :param result: list contains the data to parse ssd\n",
    "    :return: person count and frame\n",
    "    \"\"\"\n",
    "    current_count = 0\n",
    "    for obj in result[0][0]:\n",
    "        # Draw bounding box for object when it's probability is more\n",
    "        # than the specified threshold\n",
    "        if float(obj[2]) > float(prob_threshold):\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                          (0, 55, 255), 1)\n",
    "            current_count = current_count + 1\n",
    "    return frame, current_count\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the SSD output.\n",
    "\n",
    "    :return: None\n",
    "   \"\"\"\n",
    "    # Connect to the MQTT server\n",
    "    client = mqtt.Client()\n",
    "    client.connect(MQTT_HOST, MQTT_PORT, MQTT_KEEPALIVE_INTERVAL)\n",
    "\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "    # Flag for the input image\n",
    "    single_image_mode = False\n",
    "\n",
    "    cur_request_id = 0\n",
    "    last_count = 0\n",
    "    total_count = 0\n",
    "    start_time = 0\n",
    "\n",
    "    model = os.environ['MODEL']\n",
    "    device = os.environ['DEVICE'] if 'DEVICE' in os.environ.keys() else 'CPU'\n",
    "    cpu_extension = os.environ[\n",
    "        'CPU_EXTENSION'] if 'CPU_EXTENSION' in os.environ.keys() else None\n",
    "\n",
    "    # Checks for live feed\n",
    "    if os.environ['INPUT'] == 'CAM':\n",
    "        input_stream = 0\n",
    "\n",
    "    # Checks for input image\n",
    "    elif os.environ['INPUT'].endswith('.jpg') or os.environ['INPUT'].endswith('.bmp'):\n",
    "        single_image_mode = True\n",
    "        input_stream = os.environ['INPUT']\n",
    "\n",
    "    # Checks for video file\n",
    "    else:\n",
    "        input_stream = os.environ['INPUT']\n",
    "        assert os.path.isfile(os.environ['INPUT']), \"Specified input file doesn't exist\"\n",
    "\n",
    "    cap = cv2.VideoCapture(input_stream)\n",
    "\n",
    "    if input_stream:\n",
    "        cap.open(os.environ['INPUT'])\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        log.error(\"ERROR! Unable to open video source\")\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    n, c, h, w = infer_network.load_model(model, device, 1, 1,\n",
    "                                          cur_request_id, cpu_extension)[1]\n",
    "    global initial_w,initial_h\n",
    "    initial_w = cap.get(3)\n",
    "    initial_h = cap.get(4)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cmdstring = ('ffmpeg',\n",
    "                 '-y', '-r', '%d' %(fps), # overwrite, 60fps\n",
    "                 '-s', '%dx%d' % (initial_w, initial_h), # size of image string\n",
    "                 '-pixel_format' ,  'bgr24', # format\n",
    "                 '-f', 'rawvideo',  '-i', '-', # tell ffmpeg to expect raw video from the pipe\n",
    "                 'http://localhost:8090/fac.ffm') # output encoding\n",
    "    p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)\n",
    "    while cap.isOpened():\n",
    "        flag, frame = cap.read()\n",
    "        if not flag:\n",
    "            break\n",
    "        key_pressed = cv2.waitKey(60)\n",
    "        # Start async inference\n",
    "        inf_start = time.time()\n",
    "        image = cv2.resize(frame, (w, h))\n",
    "        # Change data layout from HWC to CHW\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        # Start asynchronous inference for specified request.\n",
    "        infer_network.exec_net(cur_request_id, image)\n",
    "        # Wait for the result\n",
    "        if infer_network.wait(cur_request_id) == 0:\n",
    "            det_time = time.time() - inf_start\n",
    "            # Results of the output layer of the network\n",
    "            result = infer_network.get_output(cur_request_id)\n",
    "            if os.environ['PERF_COUNTS'] > str(0):\n",
    "                perf_count = infer_network.performance_counter(cur_request_id)\n",
    "                performance_counts(perf_count)\n",
    "            frame, current_count = ssd_parser(frame, result)\n",
    "            inf_time_message = \"Inference time: {:.3f}ms\" \\\n",
    "                .format(det_time * 1000)\n",
    "            cv2.putText(frame, inf_time_message, (15, 15),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 0.5, (200, 10, 10), 1)\n",
    "\n",
    "            # When new person enters the video\n",
    "            if current_count > last_count:\n",
    "                start_time = time.time()\n",
    "                total_count = total_count + current_count - last_count\n",
    "                client.publish(\"person\", json.dumps({\"total\": total_count}))\n",
    "\n",
    "            # Person duration in the video is calculated\n",
    "            if current_count < last_count:\n",
    "                duration = int(time.time() - start_time)\n",
    "                # Publish messages to the MQTT server\n",
    "                client.publish(\"person/duration\",\n",
    "                               json.dumps({\"duration\": duration}))\n",
    "\n",
    "            client.publish(\"person\", json.dumps({\"count\": current_count}))\n",
    "            last_count = current_count\n",
    "\n",
    "            if key_pressed == 27:\n",
    "                break\n",
    "\n",
    "        p.stdin.write(frame.tostring())\n",
    "        if single_image_mode:\n",
    "            cv2.imwrite('output_image.jpg', frame)\n",
    "            infer_network.clean()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    client.disconnect()\n",
    "    infer_network.clean()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    exit(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
